{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks_cwt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.stats import iqr\n",
    "from pyentrp import entropy as ent\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#from tony_beltramelli_detect_peaks import detect_peaks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.23964512157\n"
     ]
    }
   ],
   "source": [
    "roll = [0.12, 2.56, -5.67, 8.432]\n",
    "\n",
    "rms_roll = np.sqrt(np.mean([x**2 for x in roll]))\n",
    "\n",
    "print rms_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = \"data_3_8_2018\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features for accelerometer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "def Signal_magnitude_area(x,y,z):\n",
    "\n",
    "        sum = 0    \n",
    "        for i in range(len(x)):\n",
    "            sum += (abs(x[i]) + abs(y[i]) + abs(z[i]))\n",
    "\n",
    "        return float(sum)/len(x)\n",
    "\n",
    "\n",
    "def Power(x):\n",
    "\n",
    "    power = (LA.norm(x)**2)/ len(x)\n",
    "    return power\n",
    "\n",
    "\n",
    "def number_of_peaks(window):\n",
    "    indexes = find_peaks_cwt(window, np.arange(1, len(window)))\n",
    "    return len(indexes)\n",
    "\n",
    "\n",
    "def number_of_peaks2(window):\n",
    "\n",
    "    print('Detect peaks with height threshold.')\n",
    "    indexes = detect_peaks(vector, 1.5)\n",
    "    return len(indexes)\n",
    "\n",
    "    \n",
    "def compute_accelerometer(in_dir, features, labels, ignore_pickle=False):\n",
    "    label_map = {}\n",
    "    label_map['walking']=0\n",
    "    label_map['laying_down']=1\n",
    "    label_map['sitting']=2\n",
    "    label_map['standing']=3\n",
    "    \n",
    "    trim_num_seconds = 10\n",
    "    acc_freq = 4\n",
    "    window_num_seconds = 4 #seconds\n",
    "    steps_per_sec = int(1000/acc_freq)\n",
    "    window_size = int(window_num_seconds*steps_per_sec)\n",
    "    window_step = 2 #seconds\n",
    "    window_jump_steps = int(window_step*steps_per_sec)\n",
    "\n",
    "    print(\"Window_size, Window_jump_steps: \", window_size, window_jump_steps)\n",
    "\n",
    "    #this function assumes that records are evenly spaced\n",
    "    def trim_first_last_n_seconds(df, n, freq):\n",
    "        if df.shape[0] < 6001:\n",
    "            return None\n",
    "\n",
    "        remove_indexes = list(range(0, int(n*1000/freq)))\n",
    "        df = df.drop(remove_indexes)\n",
    "\n",
    "        remove_indexes = list(range(df.shape[0] - int(n*1000/freq), df.shape[0]-1))\n",
    "        df = df.drop(remove_indexes)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    dfs_list = []\n",
    "    #features = []\n",
    "    #labels = []\n",
    "\n",
    "    \n",
    "    pickle_file = Path(\"pickles_split/accelerometer_features.pickle\")\n",
    "\n",
    "    if pickle_file.exists():\n",
    "        print(\"Found pickle files for accelerometer\")\n",
    "        features = pickle.load(open(\"pickles_split/accelerometer_features.pickle\", \"rb\"))\n",
    "        labels = pickle.load(open(\"pickles_split/accelerometer_labels.pickle\", \"rb\"))\n",
    "        dfs_list = pickle.load(open(\"pickles_split/accelerometer_dfs_list.pickle\", \"rb\"))\n",
    "\n",
    "    else:\n",
    "\n",
    "        for root, dirs, files in os.walk(in_dir):\n",
    "            path = root.split(os.sep)\n",
    "\n",
    "            for f in files:\n",
    "                print(\"/\".join(path) + \"/\" + f)\n",
    "\n",
    "                full_path = \"/\".join(path) + \"/\" + f\n",
    "\n",
    "                if \"gyroscope\" in full_path:\n",
    "                    print(\"Skip \", full_path)\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_csv(full_path, header=None)\n",
    "\n",
    "                print(\"Before trimming: \", df.shape)\n",
    "\n",
    "                df = trim_first_last_n_seconds(df, trim_num_seconds, acc_freq)\n",
    "                if df is None:\n",
    "                    print(\"Continuing\")\n",
    "                    continue\n",
    "\n",
    "                print(\"After trimming: \", df.shape)\n",
    "\n",
    "                #Sample the data according to the size of the window with 50% overlap\n",
    "                for index in range(0, df.shape[0]-window_size, window_jump_steps):\n",
    "                    indexes = list(range(index, index + int(window_size)))\n",
    "\n",
    "                    window = df.iloc[indexes,:]\n",
    "\n",
    "                    X_list = window[1].tolist()\n",
    "                    Y_list = window[2].tolist()\n",
    "                    Z_list = window[3].tolist()\n",
    "\n",
    "\n",
    "                    #Generate the features for this window\n",
    "\n",
    "\n",
    "           # ****************** Time-Domain Features ************************* #\n",
    "\n",
    "                    #Mean of the signals\n",
    "                    mean_x = np.mean(X_list)\n",
    "                    mean_y = np.mean(Y_list)\n",
    "                    mean_z = np.mean(Z_list)\n",
    "\n",
    "                    #Variance of the signals\n",
    "                    var_x = np.var(X_list)\n",
    "                    var_y = np.var(Y_list)\n",
    "                    var_z = np.var(Z_list)\n",
    "\n",
    "                    #Number of peaks in the signals\n",
    "                    #num_peaks_x = number_of_peaks(X_list)\n",
    "                    #num_peaks_y = number_of_peaks(Y_list)\n",
    "                    #num_peaks_z = number_of_peaks(Z_list)            \n",
    "\n",
    "                    #Median of the signals\n",
    "                    median_x = np.ma.median(X_list)\n",
    "                    median_y = np.ma.median(Y_list)\n",
    "                    median_z = np.ma.median(Z_list)\n",
    "\n",
    "                    #Standard Deviation of the signals\n",
    "                    std_x = np.std(X_list)\n",
    "                    std_y = np.std(Y_list)\n",
    "                    std_z = np.std(Z_list)\n",
    "\n",
    "                    #Compute Signal Magnitude Area\n",
    "                    signal_mag_area = Signal_magnitude_area(X_list, Y_list, Z_list)\n",
    "\n",
    "                    #Maximum and Minimum values and their indexes\n",
    "                    max_x = max(X_list)\n",
    "                    #max_index_x = X_list.index(max_x)               \n",
    "                    min_x = min(X_list)\n",
    "                    #min_index_x = X_list.index(min_x)\n",
    "\n",
    "                    max_y = max(Y_list)\n",
    "                   #max_index_y = Y_list.index(max_y)              \n",
    "                    min_y = min(Y_list)\n",
    "                    #min_index_y = Y_list.index(min_y)               \n",
    "\n",
    "                    max_z = max(Z_list)\n",
    "                    #max_index_z = Z_list.index(max_z)             \n",
    "                    min_z = min(Z_list)\n",
    "                    #min_index_z = Z_list.index(min_z)\n",
    "\n",
    "\n",
    "                    #Power of X,Y and Z signals             \n",
    "                    power_x = Power(X_list)\n",
    "                    power_y = Power(Y_list)\n",
    "                    power_z = Power(Z_list)\n",
    "\n",
    "\n",
    "                    #Skewness and Kurtosis\n",
    "                    skew_x = skew(X_list)\n",
    "                    skew_y = skew(Y_list)\n",
    "                    skew_z = skew(Z_list)\n",
    "\n",
    "                    kurtosis_x = kurtosis(X_list)                \n",
    "                    kurtosis_y = kurtosis(Y_list)\n",
    "                    kurtosis_z = kurtosis(Z_list)\n",
    "\n",
    "\n",
    "                    #Entropy of the signals (Can experiment with different types of Entropy)\n",
    "                    entropy_x = ent.shannon_entropy(X_list)\n",
    "                    entropy_y = ent.shannon_entropy(Y_list)\n",
    "                    entropy_z = ent.shannon_entropy(Z_list)\n",
    "\n",
    "\n",
    "                    #Interquartile range of the signals\n",
    "                    iqr_x = iqr(X_list)\n",
    "                    iqr_y = iqr(Y_list)\n",
    "                    iqr_z = iqr(Z_list)\n",
    "\n",
    "\n",
    "                    #Cross Correlation \n",
    "                    corr_x_y = np.correlate(X_list, Y_list)[0]\n",
    "                    corr_y_z = np.correlate(Y_list, Z_list)[0]\n",
    "                    corr_x_z = np.correlate(X_list, Z_list)[0]\n",
    "\n",
    "\n",
    "                    \n",
    "                    #Pitch and Roll Information (for rotation)\n",
    "                    roll = []\n",
    "                    pitch = []\n",
    "                    for index in range(0,len(X_list)):                       \n",
    "                        roll.append(math.atan2(Y_list[index]/9.81, Z_list[index]/9.81) * 57.3)\n",
    "                        pitch.append(math.atan2(X_list[index]/9.81, Z_list[index]/9.81) * 57.3)\n",
    "                    \n",
    "                    #Mean of the roll and pitch\n",
    "                    mean_roll = np.mean(roll)\n",
    "                    mean_pitch = np.mean(pitch)\n",
    "                    \n",
    "                    #RMS of roll and pitch\n",
    "                    #rms_roll = np.sqrt(np.mean(roll**2))\n",
    "                    rms_roll = np.sqrt(np.mean([x**2 for x in roll]))\n",
    "                    rms_pitch = np.sqrt(np.mean([x**2 for x in pitch]))            \n",
    "                    #rms_pitch = np.sqrt(np.mean(pitch**2))\n",
    "                                      \n",
    "                    #Zero Crossing Rate for roll and pitch\n",
    "                    frame = roll\n",
    "                    count = len(frame)\n",
    "                    countZ = np.sum(np.abs(np.diff(np.sign(frame)))) / 2\n",
    "                    zcr_roll = np.float64(countZ) / np.float64(count-1.0)\n",
    "                    \n",
    "                    frame = pitch\n",
    "                    count = len(frame)\n",
    "                    countZ = np.sum(np.abs(np.diff(np.sign(frame)))) / 2\n",
    "                    zcr_pitch = np.float64(countZ) / np.float64(count-1.0)\n",
    "                    \n",
    "\n",
    "        # ****************** Frequency-Domain Features ************************* #\n",
    "\n",
    "\n",
    "                    coeff_X = np.fft.fft(X_list)\n",
    "                    coeff_Y = np.fft.fft(Y_list)\n",
    "                    coeff_Z = np.fft.fft(Z_list)\n",
    "\n",
    "\n",
    "                    #Normalized FFT coefficients\n",
    "                    fft_x = LA.norm(coeff_X)              \n",
    "                    fft_y = LA.norm(coeff_Y)   \n",
    "                    fft_z = LA.norm(coeff_Z)  \n",
    "\n",
    "\n",
    "                    #Energy in the frequency Domain\n",
    "                    Energy_x = sum(abs(coeff_X**2))/len(X_list)\n",
    "                    #sum(abs(coeff_X)**2)/len(x1)\n",
    "                    Energy_y = sum(abs(coeff_Y**2))/len(Y_list)\n",
    "                    Energy_z = sum(abs(coeff_Z**2))/len(Z_list)\n",
    "\n",
    "\n",
    "                    #Store the features\n",
    "                    window_feature = []\n",
    "                    window_feature.append(mean_x)\n",
    "                    window_feature.append(mean_y)\n",
    "                    window_feature.append(mean_z)\n",
    "\n",
    "                    window_feature.append(var_x)\n",
    "                    window_feature.append(var_y)\n",
    "                    window_feature.append(var_z)\n",
    "\n",
    "                    window_feature.append(median_x)\n",
    "                    window_feature.append(median_y)\n",
    "                    window_feature.append(median_z)\n",
    "\n",
    "                    window_feature.append(std_x)\n",
    "                    window_feature.append(std_y)\n",
    "                    window_feature.append(std_z)\n",
    "\n",
    "\n",
    "                    window_feature.append(signal_mag_area)\n",
    "\n",
    "                    window_feature.append(max_x)\n",
    "                    #window_feature.append(max_index_x)\n",
    "                    window_feature.append(min_x)\n",
    "                    #window_feature.append(min_index_x)\n",
    "\n",
    "                    window_feature.append(max_y)\n",
    "                    #window_feature.append(max_index_y)\n",
    "                    window_feature.append(min_y)\n",
    "                    #window_feature.append(min_index_y)\n",
    "\n",
    "                    window_feature.append(max_z)\n",
    "                    #window_feature.append(max_index_z)\n",
    "                    window_feature.append(min_z)\n",
    "                    #window_feature.append(min_index_z)\n",
    "\n",
    "                    window_feature.append(power_x)\n",
    "                    window_feature.append(power_y)\n",
    "                    window_feature.append(power_z)\n",
    "\n",
    "                    window_feature.append(skew_x)\n",
    "                    window_feature.append(kurtosis_x) \n",
    "\n",
    "                    window_feature.append(skew_y)\n",
    "                    window_feature.append(kurtosis_y) \n",
    "\n",
    "                    window_feature.append(skew_z)\n",
    "                    window_feature.append(kurtosis_z) \n",
    "\n",
    "                    window_feature.append(entropy_x)\n",
    "                    window_feature.append(entropy_y)\n",
    "                    window_feature.append(entropy_z)\n",
    "\n",
    "                    window_feature.append(iqr_x)\n",
    "                    window_feature.append(iqr_y)\n",
    "                    window_feature.append(iqr_z)\n",
    "\n",
    "                    window_feature.append(corr_x_y)\n",
    "                    window_feature.append(corr_y_z)\n",
    "                    window_feature.append(corr_x_z)\n",
    "                    \n",
    "                    window_feature.append(mean_roll)\n",
    "                    window_feature.append(mean_pitch)\n",
    "                    window_feature.append(rms_roll)\n",
    "                    window_feature.append(rms_pitch)\n",
    "                    \n",
    "                    window_feature.append(zcr_roll)\n",
    "                    window_feature.append(zcr_pitch)\n",
    "\n",
    "                    window_feature.append(fft_x)\n",
    "                    window_feature.append(fft_y)\n",
    "                    window_feature.append(fft_z)\n",
    "\n",
    "                    window_feature.append(Energy_x)\n",
    "                    window_feature.append(Energy_y)\n",
    "                    window_feature.append(Energy_z)\n",
    "\n",
    "                    #window_feature.append(num_peaks_x)\n",
    "                    #window_feature.append(num_peaks_y)\n",
    "                    #window_feature.append(num_peaks_z)\n",
    "\n",
    "                    #scale = preprocessing.minmax_scale(data, feature_range=(-0.5, 0.5))\n",
    "\n",
    "                    features.append(window_feature)\n",
    "\n",
    "                    #Store the label\n",
    "                    labels.append(label_map[df[5].iloc[1]])\n",
    "\n",
    "                dfs_list.append(df)\n",
    "\n",
    "        dfs = pd.concat(dfs_list)\n",
    "\n",
    "        if not ignore_pickle:\n",
    "\n",
    "            pickle.dump(features, open(\"pickles_split/accelerometer_features.pickle\", \"wb\"), protocol=2)\n",
    "            pickle.dump(labels, open(\"pickles_split/accelerometer_labels.pickle\", \"wb\"), protocol=2)\n",
    "            pickle.dump(dfs_list, open(\"pickles_split/accelerometer_dfs_list.pickle\", \"wb\"), protocol=2)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel(modelName, args):\n",
    "    \n",
    "    if modelName == 'LogisticRegression':\n",
    "        model = LogisticRegression(random_state=42)\n",
    "        \n",
    "    if modelName == 'SVC':\n",
    "        model = SVC(random_state=42, kernel=args[0], C=args[1], decision_function_shape=args[2])\n",
    "        \n",
    "    if modelName == 'DecisionTreeClassifier':\n",
    "        model = DecisionTreeClassifier(random_state=42, max_features=args[0], criterion=args[1])\n",
    "        \n",
    "    if modelName == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(n_estimators=args[0], criterion=args[1], max_features=args[2], max_depth=args[3], oob_score=True, random_state=42)\n",
    "        \n",
    "    if modelName == 'MLPClassifier':\n",
    "        model = MLPClassifier(hidden_layer_sizes=args[0], activation=args[1], solver=args[2], random_state=42, max_iter=500)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_kfold(features, labels, num_splits, modelName, args=None, verbose=False):\n",
    "    \n",
    "    X = np.array(normalize(features))\n",
    "    y = np.array(labels)\n",
    "\n",
    "    kf = KFold(n_splits=num_splits, random_state=None, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    foldAccuracy = list()\n",
    "    foldPrecision = list()\n",
    "    foldRecall = list()\n",
    "    bestModel = None\n",
    "    bestAccuracy = float(sys.maxsize) * (-1)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = getModel(modelName, args)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        prediction = model.predict(X_test)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nFold: \", fold)\n",
    "            print(\"Confusion Matrix:\")\n",
    "            cm = metrics.confusion_matrix(yTest, prediction)\n",
    "            print(cm)\n",
    "            plt.matshow(cm, cmap = plt.cm.Oranges)\n",
    "            plt.title('Confusion matrix')\n",
    "            plt.colorbar()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            plt.show()\n",
    "\n",
    "        accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "        precision = metrics.precision_score(y_test, prediction, average = None)\n",
    "        recall = metrics.recall_score(y_test, prediction, average = None)\n",
    "\n",
    "        foldAccuracy.append(accuracy)\n",
    "        foldPrecision.append(precision)\n",
    "        foldRecall.append(recall)\n",
    "        \n",
    "        if accuracy > bestAccuracy:\n",
    "            bestAccuracy = accuracy\n",
    "            bestModel = model\n",
    "                \n",
    "    print(\"\\nBest Accuracy: \", bestAccuracy)\n",
    "    \n",
    "    return bestModel, foldAccuracy, foldPrecision, foldRecall        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "def module_1(features,labels, test_features,test_labels):\n",
    "    print(features.shape)\n",
    "    #print(labels.shape)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    #X = scaler.fit_transform(features)\n",
    "    X = features\n",
    "    #X = np.array(preprocessing.scale(features))\n",
    "    y = le.fit_transform(labels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    #model = LogisticRegression(penalty='l1')\n",
    "    #model = MLPClassifier(hidden_layer_sizes=(50,100), activation='tanh', solver='lbfgs', random_state=42, max_iter=500)\n",
    "    model = DecisionTreeClassifier(random_state=42, max_features=25, criterion='gini')\n",
    "    #model = XGBClassifier()\n",
    "    #model = RandomForestClassifier(n_estimators=40, criterion='gini', max_features=10, max_depth=15,random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    X = X_test\n",
    "    y = y_test\n",
    "    prediction = model.predict(X)\n",
    "    accuracy = metrics.accuracy_score(y, prediction)\n",
    "    precision = metrics.precision_score(y, prediction, average = None)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    cnf_matrix = confusion_matrix(y,prediction)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=le.classes_,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    X = features\n",
    "    y = le.fit_transform(labels)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    X = test_features\n",
    "    y = le.transform(test_labels)\n",
    "\n",
    "    #X = X_test\n",
    "    #y = y_test\n",
    "\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "\n",
    "    prediction_test = model.predict(X)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y, prediction_test)\n",
    "    precision = metrics.precision_score(y, prediction_test, average = None)\n",
    "    # recall = metrics.recall_score(y_test, prediction, average = None)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    cnf_matrix = confusion_matrix(y,prediction_test)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=le.classes_,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    return prediction, prediction_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Window_size, Window_jump_steps: ', 1000, 500)\n",
      "data_3_8_2018/0_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (40642, 6))\n",
      "('After trimming: ', (35643, 6))\n",
      "data_3_8_2018/0_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/0_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/10_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (137412, 6))\n",
      "('After trimming: ', (132413, 6))\n",
      "data_3_8_2018/10_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/10_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/11_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (100066, 6))\n",
      "('After trimming: ', (95067, 6))\n",
      "data_3_8_2018/11_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/11_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/12_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (64964, 6))\n",
      "('After trimming: ', (59965, 6))\n",
      "data_3_8_2018/12_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/12_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/13_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (50274, 6))\n",
      "('After trimming: ', (45275, 6))\n",
      "data_3_8_2018/13_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/13_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/14_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (59060, 6))\n",
      "('After trimming: ', (54061, 6))\n",
      "data_3_8_2018/14_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/14_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/15_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (55316, 6))\n",
      "('After trimming: ', (50317, 6))\n",
      "data_3_8_2018/15_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/15_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/16_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (48531, 6))\n",
      "('After trimming: ', (43532, 6))\n",
      "data_3_8_2018/16_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/16_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/17_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (63094, 6))\n",
      "('After trimming: ', (58095, 6))\n",
      "data_3_8_2018/17_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/17_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/18_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (63971, 6))\n",
      "('After trimming: ', (58972, 6))\n",
      "data_3_8_2018/18_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/18_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/19_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (64212, 6))\n",
      "('After trimming: ', (59213, 6))\n",
      "data_3_8_2018/19_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/19_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/1_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (33446, 6))\n",
      "('After trimming: ', (28447, 6))\n",
      "data_3_8_2018/1_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/1_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/20_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (64175, 6))\n",
      "('After trimming: ', (59176, 6))\n",
      "data_3_8_2018/20_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/20_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/21_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (52095, 6))\n",
      "('After trimming: ', (47096, 6))\n",
      "data_3_8_2018/21_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/21_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/22_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (64675, 6))\n",
      "('After trimming: ', (59676, 6))\n",
      "data_3_8_2018/22_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/22_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/23_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (66938, 6))\n",
      "('After trimming: ', (61939, 6))\n",
      "data_3_8_2018/23_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/23_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/24_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (60980, 6))\n",
      "('After trimming: ', (55981, 6))\n",
      "data_3_8_2018/24_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/24_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/25_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (62506, 6))\n",
      "('After trimming: ', (57507, 6))\n",
      "data_3_8_2018/25_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/25_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/26_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (65108, 6))\n",
      "('After trimming: ', (60109, 6))\n",
      "data_3_8_2018/26_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/26_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/27_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (62588, 6))\n",
      "('After trimming: ', (57589, 6))\n",
      "data_3_8_2018/27_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/27_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/28_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (82181, 6))\n",
      "('After trimming: ', (77182, 6))\n",
      "data_3_8_2018/28_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/28_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/29_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (83784, 6))\n",
      "('After trimming: ', (78785, 6))\n",
      "data_3_8_2018/29_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/29_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/2_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (53344, 6))\n",
      "('After trimming: ', (48345, 6))\n",
      "data_3_8_2018/2_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/2_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/30_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (85978, 6))\n",
      "('After trimming: ', (80979, 6))\n",
      "data_3_8_2018/30_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/30_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/31_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (101168, 6))\n",
      "('After trimming: ', (96169, 6))\n",
      "data_3_8_2018/31_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/31_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/32_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (53812, 6))\n",
      "('After trimming: ', (48813, 6))\n",
      "data_3_8_2018/32_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/32_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/33_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (65720, 6))\n",
      "('After trimming: ', (60721, 6))\n",
      "data_3_8_2018/33_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/33_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/34_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (71074, 6))\n",
      "('After trimming: ', (66075, 6))\n",
      "data_3_8_2018/34_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/34_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/35_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (30053, 6))\n",
      "('After trimming: ', (25054, 6))\n",
      "data_3_8_2018/35_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/35_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/36_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (26070, 6))\n",
      "('After trimming: ', (21071, 6))\n",
      "data_3_8_2018/36_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/36_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/37_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (66885, 6))\n",
      "('After trimming: ', (61886, 6))\n",
      "data_3_8_2018/37_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/37_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/38_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (68901, 6))\n",
      "('After trimming: ', (63902, 6))\n",
      "data_3_8_2018/38_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/38_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/39_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (69512, 6))\n",
      "('After trimming: ', (64513, 6))\n",
      "data_3_8_2018/39_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/39_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/3_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (31018, 6))\n",
      "('After trimming: ', (26019, 6))\n",
      "data_3_8_2018/3_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/3_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/40_1_android.sensor.accelerometer.data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before trimming: ', (67293, 6))\n",
      "('After trimming: ', (62294, 6))\n",
      "data_3_8_2018/40_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/40_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/41_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (67641, 6))\n",
      "('After trimming: ', (62642, 6))\n",
      "data_3_8_2018/41_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/41_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/42_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (40200, 6))\n",
      "('After trimming: ', (35201, 6))\n",
      "data_3_8_2018/42_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/42_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/43_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (118805, 6))\n",
      "('After trimming: ', (113806, 6))\n",
      "data_3_8_2018/43_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/43_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/44_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (65634, 6))\n",
      "('After trimming: ', (60635, 6))\n",
      "data_3_8_2018/44_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/44_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/45_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (98968, 6))\n",
      "('After trimming: ', (93969, 6))\n",
      "data_3_8_2018/45_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/45_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/46_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (96365, 6))\n",
      "('After trimming: ', (91366, 6))\n",
      "data_3_8_2018/46_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/46_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/47_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (2323, 6))\n",
      "Continuing\n",
      "data_3_8_2018/47_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/47_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/48_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (43060, 6))\n",
      "('After trimming: ', (38061, 6))\n",
      "data_3_8_2018/48_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/48_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/49_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (83999, 6))\n",
      "('After trimming: ', (79000, 6))\n",
      "data_3_8_2018/49_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/49_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/4_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (51852, 6))\n",
      "('After trimming: ', (46853, 6))\n",
      "data_3_8_2018/4_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/4_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/50_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (65899, 6))\n",
      "('After trimming: ', (60900, 6))\n",
      "data_3_8_2018/50_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/50_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/51_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (89512, 6))\n",
      "('After trimming: ', (84513, 6))\n",
      "data_3_8_2018/51_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/51_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/52_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (59739, 6))\n",
      "('After trimming: ', (54740, 6))\n",
      "data_3_8_2018/52_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/52_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/53_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (57828, 6))\n",
      "('After trimming: ', (52829, 6))\n",
      "data_3_8_2018/53_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/53_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/54_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (35267, 6))\n",
      "('After trimming: ', (30268, 6))\n",
      "data_3_8_2018/54_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/54_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/55_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (52974, 6))\n",
      "('After trimming: ', (47975, 6))\n",
      "data_3_8_2018/55_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/55_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/56_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (147020, 6))\n",
      "('After trimming: ', (142021, 6))\n",
      "data_3_8_2018/56_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/56_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/57_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (99784, 6))\n",
      "('After trimming: ', (94785, 6))\n",
      "data_3_8_2018/57_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/57_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/58_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (9650, 6))\n",
      "('After trimming: ', (4651, 6))\n",
      "data_3_8_2018/58_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/58_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/59_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (73355, 6))\n",
      "('After trimming: ', (68356, 6))\n",
      "data_3_8_2018/59_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/59_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/5_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (49109, 6))\n",
      "('After trimming: ', (44110, 6))\n",
      "data_3_8_2018/5_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/5_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/60_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (177495, 6))\n",
      "('After trimming: ', (172496, 6))\n",
      "data_3_8_2018/60_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/60_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/61_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (165062, 6))\n",
      "('After trimming: ', (160063, 6))\n",
      "data_3_8_2018/61_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/61_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/62_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (355411, 6))\n",
      "('After trimming: ', (350412, 6))\n",
      "data_3_8_2018/62_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/62_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/63_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (149453, 6))\n",
      "('After trimming: ', (144454, 6))\n",
      "data_3_8_2018/63_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/63_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/64_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (138601, 6))\n",
      "('After trimming: ', (133602, 6))\n",
      "data_3_8_2018/64_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/64_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/65_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (106594, 6))\n",
      "('After trimming: ', (101595, 6))\n",
      "data_3_8_2018/65_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/65_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/66_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (168816, 6))\n",
      "('After trimming: ', (163817, 6))\n",
      "data_3_8_2018/66_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/66_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/67_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (225124, 6))\n",
      "('After trimming: ', (220125, 6))\n",
      "data_3_8_2018/67_4_android.sensor.gyroscope.data.csv\n",
      "('Skip ', 'data_3_8_2018/67_4_android.sensor.gyroscope.data.csv')\n",
      "data_3_8_2018/68_1_android.sensor.accelerometer.data.csv\n",
      "('Before trimming: ', (317906, 6))\n",
      "('After trimming: ', (312907, 6))\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "test = True\n",
    "\n",
    "test_dir = 'test3'\n",
    "train_dir = 'data_3_8_2018'\n",
    "\n",
    "if train:\n",
    "    features = []\n",
    "    labels = []\n",
    "    features, labels = compute_accelerometer(train_dir, features, labels, ignore_pickle=False)\n",
    "    \n",
    "if test:\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    test_features, test_labels = compute_accelerometer(test_dir, test_features, test_labels, ignore_pickle=True)\n",
    "\n",
    "print features.shape\n",
    "print test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mod1 = ['not_walking' if not x=='walking' else 'walking' for x in labels]\n",
    "test_labels_mod1 = ['not_walking' if not x=='walking' else 'walking' for x in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mod1, prediction_test_mod1 = module_1(features,labels, test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bool_filter(lst, bools):\n",
    "    nl = []\n",
    "    for i,j in zip(lst,bools):\n",
    "        if(j):\n",
    "            nl.append(i)\n",
    "    return nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_mod2 = [False if x=='walking' else True for x in prediction]\n",
    "test_labels_mod2 = [False if x=='walking' else True for x in prediction_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_mod2 = get_bool_filter(features,labels_mod2)\n",
    "test_features_mod2 = get_bool_filter(test_features,test_labels_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_mod2, prediction_test_mod2 = module_1(features_mod2,labels_mod2, test_features_mod2,test_labels_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "print(le.classes_)\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
